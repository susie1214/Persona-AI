# ui/chat_dock.py
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QLineEdit, QPushButton, QLabel,
    QHBoxLayout, QComboBox, QListWidget, QListWidgetItem, QListView
)
from PySide6.QtGui import QIcon, QPixmap
from PySide6.QtCore import QSize, Qt, QThread, Signal, QObject
from typing import Optional

from core.llm_router import LLMRouter
from core.digital_persona import DigitalPersonaManager


# ========== LLM ë¹„ë™ê¸° Worker ==========
class LLMWorker(QObject):
    """LLM í˜¸ì¶œì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬í•˜ëŠ” Worker"""
    sig_done = Signal(str)  # ì„±ê³µ ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸
    sig_error = Signal(str)  # ì˜¤ë¥˜ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€

    def __init__(self, router, backend, prompt, temperature, max_new_tokens=None):
        super().__init__()
        self.router = router
        self.backend = backend
        self.prompt = prompt
        self.temperature = temperature
        self.max_new_tokens = max_new_tokens

    def run(self):
        """LLM í˜¸ì¶œ ì‹¤í–‰ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)"""
        try:
            # max_new_tokensê°€ ì„¤ì •ë˜ì—ˆìœ¼ë©´ ì „ë‹¬ (Kanana ë“± ì§€ì›í•˜ëŠ” ëª¨ë¸ìš©)
            kwargs = {"temperature": self.temperature}
            if self.max_new_tokens is not None:
                kwargs["max_new_tokens"] = self.max_new_tokens

            answer = self.router.complete(self.backend, self.prompt, **kwargs)
            self.sig_done.emit(answer)
        except Exception as e:
            import traceback
            error_msg = f"LLM ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}"
            self.sig_error.emit(error_msg)


# ë°±ì—”ë“œ ì´ë¦„ â†’ ë””ìŠ¤í”Œë ˆì´ëª…/ì•„ì´ì½˜ ê²½ë¡œ ë§¤í•‘ (ìš”ì²­ ê²½ë¡œ ì‚¬ìš©)
AVATAR_PATHS = {
    "user": ("You", "resources/user.png"),
    "openai:gpt-4o-mini": ("ChatGPT", "resources/chatgpt.png"),
    "llama3": ("Llama 3", "resources/llama.png"),
    "A_X-4.0": ("A.(ì—ì´ë‹·)", "resources/aidot.png"),
    "Midm-2.0-Mini-Instruct": ("ë¯¿:ìŒK 2.0", "resources/mideumk.png"),
    "kanana": ("ì¹´ë‚˜ë‚˜", "resources/kanana.png")
}

def _icon_from(path: str) -> QIcon:
    pm = QPixmap(path)
    if pm.isNull():
        return QIcon()
    return QIcon(pm)

def _norm_backend_key(text: str) -> str:
    """
    ì½¤ë³´ë°•ìŠ¤ì— ë“¤ì–´ê°€ëŠ” í‘œì‹œ ë¬¸ìì—´ì„ AVATAR_PATHS í‚¤ë¡œ ì •ê·œí™”.
    - 'ollama:llama3' -> 'llama3'
    - 'ax:A.X-4.0'    -> 'A_X-4.0'
    - 'midm:Midm-2.0-Mini-Instruct' -> 'Midm-2.0-Mini-Instruct'
    - ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
    """
    if ":" in text:
        left, right = text.split(":", 1)
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ë§µí•‘
        if left == "ollama":
            return right
        if left == "ax":
            return "A_X-4.0"
        if left == "midm":
            return right
    return text


class ChatDock(QWidget):
    """
    Persona Chatbot íŒ¨ë„
    - ìƒë‹¨: Persona ì„ íƒ (BackendëŠ” í˜ë¥´ì†Œë‚˜ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
    - ì¤‘ì•™: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸(QListWidget, ì•„ì´ì½˜ í¬í•¨)
    - í•˜ë‹¨: ì…ë ¥ì°½ + Send (Enterë¡œë„ ì „ì†¡)
    """
    def __init__(self, rag_store=None, persona_manager: Optional[DigitalPersonaManager] = None, default_backend: str = "openai:gpt-4o-mini", parent=None):
        super().__init__(parent)
        self.rag_store = rag_store
        self.persona_manager = persona_manager
        self.router = LLMRouter()
        self.active_persona_id = None  # í˜„ì¬ ì„ íƒëœ í˜ë¥´ì†Œë‚˜ speaker_id
        self._system_prompt = "You are a helpful assistant."
        self._current_backend = default_backend  # ê¸°ë³¸ ë°±ì—”ë“œ (Settingsì—ì„œ ì„¤ì • ê°€ëŠ¥)
        self.setMinimumWidth(360)

        # LLM ë¹„ë™ê¸° ì²˜ë¦¬ìš©
        self.llm_thread = None
        self.llm_worker = None
        self._current_context = ""  # RAG ì»¨í…ìŠ¤íŠ¸ ì„ì‹œ ì €ì¥

        layout = QVBoxLayout(self)

        # === ìƒë‹¨ Persona ì„ íƒ ===
        row = QHBoxLayout()
        row.addWidget(QLabel("ëŒ€í™” ìƒëŒ€"))
        self.cmb_persona = QComboBox()
        self.load_personas()
        self.cmb_persona.currentTextChanged.connect(self.on_persona_changed)
        row.addWidget(self.cmb_persona)

        row.addWidget(QLabel("Backend"))
        self.lbl_backend = QLabel("openai:gpt-4o-mini")
        self.lbl_backend.setStyleSheet("color: #6B7280; font-style: italic;")
        row.addWidget(self.lbl_backend)

        layout.addLayout(row)

        # === ì¤‘ì•™: ëŒ€í™” ë·° (ì•„ì´ì½˜ í¬í•¨ ë¦¬ìŠ¤íŠ¸) ===
        self.view = QListWidget()
        self.view.setIconSize(QSize(40, 40))
        self.view.setUniformItemSizes(False)
        self.view.setResizeMode(QListView.ResizeMode.Adjust)
        self.view.setWordWrap(True)
        # í…ìŠ¤íŠ¸ ë“œë˜ê·¸ ì„ íƒ ë° ë³µì‚¬ í™œì„±í™”
        self.view.setSelectionMode(QListWidget.SelectionMode.ExtendedSelection)
        layout.addWidget(self.view, 1)

        # ì´ˆê¸° ìƒíƒœ ì•ˆë‚´ (ì£¼ì„ ì²˜ë¦¬ - ëŒ€ë‹µë§Œ í‘œì‹œ)
        # self._append_status(f"ğŸ§­ ëŒ€í™” ìƒëŒ€: ì—†ìŒ (íšŒì‚¬ ì „ì²´ ì±—ë´‡) | backend: {self._current_backend}")

        # === í•˜ë‹¨: ì…ë ¥ ===
        sub = QHBoxLayout()
        self.edit = QLineEdit()
        self.edit.setPlaceholderText("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")
        self.btn = QPushButton("Send")
        sub.addWidget(self.edit, 1)
        sub.addWidget(self.btn)
        layout.addLayout(sub)

        self.btn.clicked.connect(self.on_send)
        # Enter í‚¤ëŠ” LLM ì²˜ë¦¬ ì¤‘ì¼ ë•Œ ë¬´ì‹œë˜ë„ë¡ on_sendì—ì„œ ì²˜ë¦¬
        self.edit.returnPressed.connect(self._on_enter_pressed)

    def _on_enter_pressed(self):
        """Enter í‚¤ ì…ë ¥ ì²˜ë¦¬ (LLM ì²˜ë¦¬ ì¤‘ì´ë©´ ë¬´ì‹œ)"""
        # LLM ì²˜ë¦¬ ì¤‘ì´ë©´ ì—”í„° í‚¤ ë¬´ì‹œ
        if self.llm_thread and self.llm_thread.isRunning():
            return
        self.on_send()

    # ---------- í˜ë¥´ì†Œë‚˜ ê´€ë¦¬ ----------
    def load_personas(self):
        """í˜ë¥´ì†Œë‚˜ ëª©ë¡ ë¡œë“œ (ë“œë¡­ë‹¤ìš´ ê°±ì‹ )"""
        self.cmb_persona.clear()
        self.cmb_persona.addItem("ì—†ìŒ (íšŒì‚¬ ì „ì²´)")

        if self.persona_manager:
            personas = self.persona_manager.get_all_personas()
            for persona in personas:
                display_text = f"{persona.display_name} ({persona.speaker_id})"
                self.cmb_persona.addItem(display_text, userData=persona.speaker_id)

    def refresh_personas(self):
        """ì™¸ë¶€ì—ì„œ í˜ë¥´ì†Œë‚˜ ê°±ì‹  ìš”ì²­ ì‹œ í˜¸ì¶œ"""
        current_text = self.cmb_persona.currentText()
        self.load_personas()
        # ê¸°ì¡´ ì„ íƒ ìœ ì§€ ì‹œë„
        index = self.cmb_persona.findText(current_text)
        if index >= 0:
            self.cmb_persona.setCurrentIndex(index)

    def set_default_backend(self, backend: str):
        """
        ê¸°ë³¸ LLM ë°±ì—”ë“œ ì„¤ì • (Settingsì—ì„œ í˜¸ì¶œ)

        Args:
            backend: ë°±ì—”ë“œ ID (ì˜ˆ: "openai:gpt-4o-mini")
        """
        # ëª¨ë“  ì±„íŒ…ì— Settingsì˜ ê¸°ë³¸ ë°±ì—”ë“œ ì‚¬ìš©
        self._current_backend = backend
        self.lbl_backend.setText(backend)
        # ë°±ì—”ë“œ ë³€ê²½ ë©”ì‹œì§€ ì œê±° (ëŒ€ë‹µë§Œ í‘œì‹œ)
        # self._append_status(f"ğŸ”§ ê¸°ë³¸ LLM ë°±ì—”ë“œ ë³€ê²½: {backend}")

    # ---------- ë‚´ë¶€ ìœ í‹¸ ----------
    def _current_backend_key(self) -> str:
        return _norm_backend_key(self._current_backend)

    def _append_status(self, text: str):
        it = QListWidgetItem(text)
        it.setFlags(it.flags()) #  & ~Qt.ItemFlag.ItemIsSelectable
        self.view.addItem(it)
        self.view.scrollToBottom()

    def _append_message(self, role: str, text: str, backend_key: str | None = None):
        """
        role: 'user' | 'assistant' (assistantì¼ ë•Œ backend_key ì‚¬ìš©)
        """
        if role == "user":
            disp, icon_path = AVATAR_PATHS.get("user", ("You", ""))
            label = disp
            icon = _icon_from(icon_path)
        else:
            key = backend_key or self._current_backend_key()
            disp, icon_path = AVATAR_PATHS.get(key, (key, ""))
            label = disp
            icon = _icon_from(icon_path)

        # ë¼ë²¨ + ë³¸ë¬¸(ë‘ ì¤„)
        text_block = f"{label}\n{text}"
        it = QListWidgetItem(icon, text_block)
        # í…ìŠ¤íŠ¸ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
        it.setFlags(it.flags() | Qt.ItemFlag.ItemIsSelectable)
        # ëŒ€ì¶© ë†’ì´ ê°€ëŠ (ë³¸ë¬¸ ê¸¸ì´ì— ë”°ë¼ ëŠ˜ë ¤ì¤Œ)
        # approx_lines = max(1, len(text) // 38 + 1)
        # it.setSizeHint(QSize(0, 26 + approx_lines * 18))
        self.view.addItem(it)
        self.view.scrollToBottom()

    # ---------- ì´ë²¤íŠ¸ ----------
    def on_persona_changed(self, display_text: str):
        """í˜ë¥´ì†Œë‚˜ ì„ íƒ ë³€ê²½ ì‹œ"""
        if display_text.startswith("ì—†ìŒ"):
            # íšŒì‚¬ ì „ì²´ ì±—ë´‡ - Settingsì—ì„œ ì„¤ì •í•œ ê¸°ë³¸ ë°±ì—”ë“œ ì‚¬ìš©
            self.active_persona_id = None
            self._system_prompt = "You are a helpful assistant."
            # self._current_backendëŠ” ì´ˆê¸°í™” ì‹œ ë˜ëŠ” set_default_backend()ë¡œ ì´ë¯¸ ì„¤ì •ë¨
            self.lbl_backend.setText(self._current_backend)
            # í˜ë¥´ì†Œë‚˜ ë³€ê²½ ë©”ì‹œì§€ ì œê±° (ëŒ€ë‹µë§Œ í‘œì‹œ)
            # self._append_status(f"ğŸ§­ ëŒ€í™” ìƒëŒ€: ì—†ìŒ (íšŒì‚¬ ì „ì²´ ì±—ë´‡) | backend: {self._current_backend}")
            return

        # í˜ë¥´ì†Œë‚˜ ì„ íƒ - Settingsì—ì„œ ì„¤ì •í•œ ê¸°ë³¸ ë°±ì—”ë“œ ì‚¬ìš©
        index = self.cmb_persona.currentIndex()
        speaker_id = self.cmb_persona.itemData(index)

        if not speaker_id or not self.persona_manager:
            return

        persona = self.persona_manager.get_persona(speaker_id)
        if not persona:
            return

        self.active_persona_id = speaker_id
        self._system_prompt = persona.generate_system_prompt()
        # í˜ë¥´ì†Œë‚˜ë³„ ë°±ì—”ë“œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê³ , Settingsì˜ ê¸°ë³¸ ë°±ì—”ë“œ ì‚¬ìš©
        # self._current_backendëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (Settingsì—ì„œ ì„¤ì •í•œ ê°’)
        self.lbl_backend.setText(self._current_backend)

        # í˜ë¥´ì†Œë‚˜ ë³€ê²½ ë©”ì‹œì§€ ì œê±° (ëŒ€ë‹µë§Œ í‘œì‹œ)
        # self._append_status(
        #     f"ğŸ§­ ëŒ€í™” ìƒëŒ€: {persona.display_name} | backend: {self._current_backend}"
        # )

    def on_send(self):
        q = self.edit.text().strip()
        if not q:
            return

        # ì´ë¯¸ LLM ì²˜ë¦¬ ì¤‘ì´ë©´ ë¬´ì‹œ
        if self.llm_thread and self.llm_thread.isRunning():
            self._append_status("âš ï¸ ì´ì „ ìš”ì²­ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            return

        self.edit.clear()
        print(f"[DEBUG] User Query: {q}")

        # ì‚¬ìš©ì ë©”ì‹œì§€ ë Œë”
        self._append_message("user", q)

        # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        context_block = ""
        if self.rag_store and self.rag_store.ok:
            ctx = self.rag_store.search(q, topk=3)
            print(f"[DEBUG - chat_dock] searched context : {ctx}")
            if ctx:
                context_lines = ["[ê´€ë ¨ íšŒì˜ ë‚´ìš©]", "-" * 20]
                for c in ctx:
                    context_lines.append(f"- {c.get('text', '')}")
                context_block = "\n".join(context_lines)

        print(f"[DEBUG] RAG Context:\n{context_block}")
        self._current_context = context_block  # ë‚˜ì¤‘ì— ì‘ë‹µì— ì¶”ê°€í•˜ê¸° ìœ„í•´ ì €ì¥

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        sys_prompt = self._system_prompt
        backend_label = self._current_backend  # í˜ë¥´ì†Œë‚˜ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ë°±ì—”ë“œ ì‚¬ìš©

        # Kanana ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ í¬ë§· (ë‹¨ì¼ í„´ ìƒì„±)
        prompt = f"{sys_prompt}\n\n"
        if context_block:
            prompt += f"{context_block}\n\n"
        prompt += f"ì‚¬ìš©ì: {q}\nì–´ì‹œìŠ¤í„´íŠ¸: "  # Kanana ì±„íŒ… í¬ë§·

        # "ìƒê° ì¤‘..." ë©”ì‹œì§€ ì œê±° (ëŒ€ë‹µë§Œ í‘œì‹œ)
        # self._append_status("ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘...")

        # UI ì…ë ¥ ë¹„í™œì„±í™”
        self.btn.setEnabled(False)
        self.edit.setEnabled(False)

        # ë¹„ë™ê¸° LLM í˜¸ì¶œ
        self.llm_thread = QThread()
        # Kanana ëª¨ë¸ì˜ ê²½ìš° max_new_tokensë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œí•œí•˜ì—¬ ê³¼ë„í•œ ìƒì„± ë°©ì§€
        self.llm_worker = LLMWorker(self.router, backend_label, prompt, temperature=0.3, max_new_tokens=512)
        self.llm_worker.moveToThread(self.llm_thread)

        # ì‹œê·¸ë„ ì—°ê²°
        self.llm_thread.started.connect(self.llm_worker.run)
        self.llm_worker.sig_done.connect(self._on_llm_done)
        self.llm_worker.sig_error.connect(self._on_llm_error)
        self.llm_worker.sig_done.connect(self.llm_thread.quit)
        self.llm_worker.sig_error.connect(self.llm_thread.quit)
        self.llm_thread.finished.connect(self._on_llm_finished)

        # ìŠ¤ë ˆë“œ ì‹œì‘
        self.llm_thread.start()

    def _on_llm_done(self, answer: str):
        """LLM ì‘ë‹µ ì„±ê³µ"""
        backend_key = self._current_backend_key()

        # RAG ì»¨í…ìŠ¤íŠ¸ ì œê±° - ëŒ€ë‹µë§Œ í‘œì‹œ
        final_ans = answer
        # if self._current_context:
        #     final_ans += f"\n\n---\n{self._current_context}"

        self._append_message("assistant", final_ans, backend_key=backend_key)

    def _on_llm_error(self, error_msg: str):
        """LLM ì˜¤ë¥˜ ì²˜ë¦¬"""
        self._append_message("assistant", f"âŒ {error_msg}", backend_key=None)

    def _on_llm_finished(self):
        """LLM ì²˜ë¦¬ ì™„ë£Œ (ì„±ê³µ/ì‹¤íŒ¨ ë¬´ê´€)"""
        # UI ë‹¤ì‹œ í™œì„±í™”
        self.btn.setEnabled(True)
        self.edit.setEnabled(True)
        self._current_context = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
