# 🧠 QLoRA 자동 학습 기능 가이드

## 📋 개요

회의가 종료되면 자동으로 참여한 화자들의 말투를 QLoRA로 학습하여 디지털 페르소나를 생성합니다.

## ✨ 주요 기능

### 1. 🎯 자동 학습 트리거
- **회의 녹음 종료** 또는 **오프라인 파일 처리 완료** 시 자동으로 학습 시작
- 발언 수가 최소 기준(기본 20개)을 넘는 화자만 학습
- 백그라운드에서 실행되어 UI가 멈추지 않음

### 2. 📊 실시간 진행 상황 표시
- **Live 탭 우측 하단**에 학습 진행 상황 표시
- 프로그레스 바로 진행률 확인 (0-100%)
- 각 단계별 상태 메시지 표시:
  - 📊 데이터셋 생성 중... (0-30%)
  - 🧠 말투 학습 중... (30-90%)
  - ✅ 학습 완료! (100%)

### 3. ⚙️ 설정 옵션
**Settings 탭 → QLoRA 페르소나 학습** 섹션에서 설정 가능:

| 설정 | 기본값 | 설명 |
|-----|-------|------|
| **자동 학습** | ✅ 활성화 | 회의 종료 시 자동으로 학습 시작 |
| **최소 발언 수** | 20개 | 학습에 필요한 최소 발언 수 |

## 🚀 사용 방법

### 기본 사용 (자동)

1. **회의 시작**
   - Live 탭에서 "Start Recording" 클릭
   - 화자들이 대화 진행

2. **회의 종료**
   - "Stop Recording" 클릭
   - 자동으로 학습 진행 상황 표시

3. **학습 완료**
   - 완료 알림창 표시
   - 챗봇에서 해당 화자의 말투로 대화 가능

### 수동 설정

**Settings 탭**에서:

```
🧠 QLoRA 페르소나 학습
┌─────────────────────────────┐
│ ☑ 회의 종료 시 자동 학습      │
│ 최소 발언 수: [20]           │
└─────────────────────────────┘
```

- 자동 학습을 끄려면 체크박스 해제
- 최소 발언 수를 조정하려면 숫자 입력 (권장: 20-50)

## 📁 생성 파일 구조

```
Persona-AI/
├── data/
│   └── persona_datasets/           # 학습 데이터셋
│       └── speaker_001_dataset_20250124_143000.jsonl
│
└── adapters/                        # QLoRA 어댑터
    └── speaker_001/
        └── final/
            ├── adapter_config.json
            ├── adapter_model.bin
            ├── metadata.json
            └── tokenizer/
```

## 🎨 UI 구성

### Live 탭 - 학습 진행 상황

```
┌──────────────────────────────────┐
│ 🧠 김철수 말투 학습 중...         │
│ ████████████░░░░░░░░ 60%         │
│ 진행률: 60%                       │
└──────────────────────────────────┘
```

- **초록색 배경**: 정상 진행
- **빨간색 배경**: 에러 발생
- 완료 후 3초 뒤 자동으로 숨김

### Settings 탭 - 학습 설정

```
🔧 시스템 설정
┌─────────────────────────────┐
│ Whisper Model: medium        │
│ Auto Diarization: ☑          │
│ HF Token: ********           │
└─────────────────────────────┘

🧠 QLoRA 페르소나 학습
┌─────────────────────────────┐
│ ☑ 회의 종료 시 자동 학습      │
│ 최소 발언 수: 20             │
└─────────────────────────────┘
```

## 🔄 학습 프로세스

### 1단계: 데이터셋 생성 (0-30%)
```python
# RAG에서 화자 발언 추출
발언 예시:
- "데이터베이스 성능을 최적화해야 합니다"
- "인덱스를 추가하는 게 좋을 것 같아요"

# Instruction-following 포맷으로 변환
{
  "instruction": "김철수의 말투로 답변하세요",
  "input": "데이터베이스 관련 의견을 말씀해주세요",
  "output": "데이터베이스 성능을 최적화해야 합니다"
}
```

### 2단계: QLoRA 학습 (30-90%)
```
- 베이스 모델: Qwen/Qwen2.5-3B-Instruct
- 4-bit 양자화 (메모리 절약)
- LoRA rank: 16
- Epochs: 3
- Batch size: 4
```

### 3단계: 어댑터 저장 (90-100%)
```
✅ 학습 완료
- 어댑터 저장: adapters/speaker_001/final
- 페르소나에 경로 자동 등록
- 챗봇에서 즉시 사용 가능
```

## 💬 학습된 페르소나 사용

### 채팅에서 활용

1. **Persona Chatbot** 도크 열기
2. 페르소나 선택 드롭다운에서 학습된 화자 선택
3. 질문 입력 → 해당 화자의 말투로 답변

**예시:**

```
사용자: 이번 프로젝트 일정은 어떻게 되나요?

김철수 (학습된 말투):
네, 프로젝트 일정 말씀드리자면요,
현재 개발은 순조롭게 진행되고 있습니다.
다음 주까지 테스트를 완료하고,
그 다음 주에 배포하는 게 좋을 것 같아요.
```

## ⚠️ 주의사항

### 필수 요구사항

1. **PEFT 라이브러리 설치**
   ```bash
   pip install peft transformers accelerate bitsandbytes
   ```

2. **GPU 메모리**
   - 최소 6GB VRAM 권장 (4-bit 양자화 사용 시)
   - CPU로도 가능하지만 매우 느림

3. **디스크 공간**
   - 어댑터당 약 1GB
   - 데이터셋당 약 1-10MB

### 성능 최적화

| 설정 | 낮은 메모리 | 균형 | 높은 품질 |
|-----|-----------|------|---------|
| **Batch Size** | 2 | 4 | 8 |
| **Epochs** | 1 | 3 | 5 |
| **LoRA Rank** | 8 | 16 | 32 |
| **학습 시간** | ~5분 | ~15분 | ~30분 |

## 🐛 문제 해결

### 학습 실패: PEFT not available

**원인:** PEFT 라이브러리 미설치

**해결:**
```bash
pip install peft==0.17.1
pip install transformers==4.56.2
pip install accelerate==1.10.1
```

### 학습 실패: CUDA out of memory

**원인:** GPU 메모리 부족

**해결:**
1. 다른 GPU 프로그램 종료
2. Batch size 줄이기 (Settings에서 수정 필요)
3. 4-bit 양자화 확인 (기본 활성화됨)

### 학습 건너뜀: 발언 수 부족

**원인:** 해당 화자의 발언이 20개 미만

**해결:**
1. 더 긴 회의 진행
2. Settings에서 최소 발언 수 줄이기 (권장하지 않음)

**Status 탭 로그:**
```
⏭ speaker_001: 발언 수 부족 (15/20) - 학습 건너뜀
```

## 📊 학습 품질 향상 팁

### 1. 충분한 데이터 확보
- **최소:** 20개 발언
- **권장:** 50-100개 발언
- **이상적:** 200개 이상

### 2. 다양한 주제
- 한 가지 주제만 말하면 학습이 편향됨
- 여러 회의에 참여하여 다양한 발언 수집

### 3. 명확한 발음
- 음성 인식 품질이 학습에 직접 영향
- 배경 소음 최소화
- 마이크와 적절한 거리 유지

## 🎯 활용 사례

### 1. 회의록 자동 생성
```
김철수님의 페르소나로:
"이번 회의에서 논의된 내용을 요약해주세요"
→ 김철수님의 말투로 요약 생성
```

### 2. 후속 조치 제안
```
"이번 프로젝트에서 제가 해야 할 일은 무엇인가요?"
→ 회의 내용 기반 + 김철수님 스타일의 답변
```

### 3. 일정 관리
```
"다음 주 일정을 알려주세요"
→ RAG에서 일정 검색 + 김철수님 말투로 전달
```

## 📚 기술 상세

### QLoRA (Quantized Low-Rank Adaptation)

**장점:**
- 메모리 효율적 (4-bit 양자화)
- 빠른 학습 (LoRA 사용)
- 높은 품질 유지

**구조:**
```
베이스 모델 (frozen, 4-bit)
    ↓
LoRA 어댑터 (trainable, FP16)
    ↓
화자 특화 출력
```

### 학습 데이터 포맷

```json
{
  "instruction": "김철수의 말투로 답변하세요",
  "input": "데이터베이스 관련 의견을 말씀해주세요",
  "output": "데이터베이스 성능을 최적화해야 합니다",
  "speaker_id": "speaker_001",
  "speaker_name": "김철수"
}
```

### 프롬프트 템플릿

```
### Instruction:
김철수의 말투로 답변하세요

### Input:
데이터베이스 관련 의견을 말씀해주세요

### Response:
데이터베이스 성능을 최적화해야 합니다
```

## 🔗 관련 문서

- [MODEL_SETUP.md](MODEL_SETUP.md) - 모델 설치 가이드
- [RAG_USAGE.md](RAG_USAGE.md) - RAG 사용법
- [작업_내용_정리.md](작업_내용_정리.md) - 프로젝트 히스토리

## 📝 변경 이력

### v1.0.0 (2025-01-24)
- ✨ 회의 종료 시 자동 학습 기능 추가
- 🎨 실시간 진행 상황 UI 추가
- ⚙️ Settings 탭에 학습 설정 옵션 추가
- 🔄 백그라운드 학습 Worker (QThread) 구현
- 💾 DigitalPersona에 어댑터 경로 자동 저장
